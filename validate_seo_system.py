#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
üß™ Advanced SEO System Validation
‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏ö‡∏ö SEO ‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î

Features:
- ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÑ‡∏ü‡∏•‡πå HTML ‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏∂‡πâ‡∏ô
- ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Structured Data
- ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Core Web Vitals readiness
- ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå Performance optimization
"""

import json
import os
from pathlib import Path
import xml.etree.ElementTree as ET
from urllib.parse import urlparse
import re


class SEOSystemValidator:
    def __init__(self):
        self.docs_path = Path("docs")
        self.validation_results = {
            "html_files": 0,
            "structured_data": 0,
            "images_optimized": 0,
            "sitemap_urls": 0,
            "rss_items": 0,
            "errors": [],
            "warnings": []
        }

    def validate_html_files(self):
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå HTML ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"""
        print("üß™ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå HTML...")
        
        html_files = list(self.docs_path.rglob("*.html"))
        self.validation_results["html_files"] = len(html_files)
        
        for html_file in html_files:
            try:
                content = html_file.read_text(encoding="utf-8")
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö DOCTYPE
                if not content.startswith("<!DOCTYPE html>"):
                    self.validation_results["warnings"].append(f"‡πÑ‡∏°‡πà‡∏°‡∏µ DOCTYPE: {html_file.name}")
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö viewport meta tag
                if 'name="viewport"' not in content:
                    self.validation_results["warnings"].append(f"‡πÑ‡∏°‡πà‡∏°‡∏µ viewport meta: {html_file.name}")
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Structured Data
                if 'application/ld+json' in content:
                    self.validation_results["structured_data"] += 1
                    self.validate_structured_data(content, html_file.name)
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Core Web Vitals optimization
                self.validate_core_web_vitals(content, html_file.name)
                
            except Exception as e:
                self.validation_results["errors"].append(f"Error reading {html_file.name}: {e}")
        
        print(f"   ‚úÖ ‡πÑ‡∏ü‡∏•‡πå HTML: {len(html_files)} ‡πÑ‡∏ü‡∏•‡πå")

    def validate_structured_data(self, content, filename):
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Structured Data JSON-LD"""
        try:
            # ‡∏´‡∏≤ JSON-LD scripts
            json_ld_pattern = r'<script type="application/ld\+json"[^>]*>(.*?)</script>'
            matches = re.findall(json_ld_pattern, content, re.DOTALL)
            
            for match in matches:
                try:
                    # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î JSON (remove HTML entities)
                    clean_json = match.strip()
                    json.loads(clean_json)  # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ JSON valid
                except json.JSONDecodeError:
                    self.validation_results["warnings"].append(
                        f"Invalid JSON-LD in {filename}"
                    )
                    
        except Exception as e:
            self.validation_results["warnings"].append(f"JSON-LD validation error in {filename}: {e}")

    def validate_core_web_vitals(self, content, filename):
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Core Web Vitals optimization"""
        optimizations = {
            'preconnect': 'rel="preconnect"' in content,
            'preload': 'rel="preload"' in content,
            'lazy_loading': 'loading="lazy"' in content,
            'critical_css': '<style>' in content,  # Inline CSS
            'async_script': 'async' in content or 'defer' in content,
            'image_alt': 'alt=' in content
        }
        
        missing_optimizations = [opt for opt, present in optimizations.items() if not present]
        
        if missing_optimizations and filename != "sample-optimized-gallery.html":
            self.validation_results["warnings"].append(
                f"Missing optimizations in {filename}: {', '.join(missing_optimizations)}"
            )

    def validate_sitemap(self):
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Sitemap XML"""
        print("üó∫Ô∏è ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Sitemap...")
        
        sitemap_path = self.docs_path / "sitemap.xml"
        if not sitemap_path.exists():
            self.validation_results["errors"].append("‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå sitemap.xml")
            return
        
        try:
            tree = ET.parse(sitemap_path)
            root = tree.getroot()
            
            # ‡∏ô‡∏±‡∏ö URLs
            urls = root.findall(".//{http://www.sitemaps.org/schemas/sitemap/0.9}url")
            self.validation_results["sitemap_urls"] = len(urls)
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö required elements
            for url in urls[:5]:  # ‡∏ï‡∏£‡∏ß‡∏à‡πÅ‡∏Ñ‡πà 5 URL ‡πÅ‡∏£‡∏Å
                loc = url.find("{http://www.sitemaps.org/schemas/sitemap/0.9}loc")
                lastmod = url.find("{http://www.sitemaps.org/schemas/sitemap/0.9}lastmod")
                
                if loc is None:
                    self.validation_results["errors"].append("URL ‡πÉ‡∏ô sitemap ‡πÑ‡∏°‡πà‡∏°‡∏µ loc element")
                if lastmod is None:
                    self.validation_results["warnings"].append("URL ‡πÉ‡∏ô sitemap ‡πÑ‡∏°‡πà‡∏°‡∏µ lastmod")
            
            print(f"   ‚úÖ Sitemap URLs: {len(urls)} URLs")
            
        except Exception as e:
            self.validation_results["errors"].append(f"Sitemap validation error: {e}")

    def validate_rss_feed(self):
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö RSS Feed"""
        print("üì° ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö RSS Feed...")
        
        rss_path = self.docs_path / "feed.xml"
        if not rss_path.exists():
            self.validation_results["errors"].append("‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå feed.xml")
            return
        
        try:
            tree = ET.parse(rss_path)
            root = tree.getroot()
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö RSS version
            if root.tag != "rss" or root.get("version") != "2.0":
                self.validation_results["errors"].append("RSS feed format incorrect")
            
            # ‡∏ô‡∏±‡∏ö items
            items = root.findall(".//item")
            self.validation_results["rss_items"] = len(items)
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö required elements
            channel = root.find("channel")
            if channel is None:
                self.validation_results["errors"].append("RSS feed ‡πÑ‡∏°‡πà‡∏°‡∏µ channel element")
            
            print(f"   ‚úÖ RSS Items: {len(items)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
            
        except Exception as e:
            self.validation_results["errors"].append(f"RSS validation error: {e}")

    def validate_pwa_files(self):
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå PWA"""
        print("üì± ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö PWA Files...")
        
        pwa_files = {
            "manifest.json": "Web App Manifest",
            "sw.js": "Service Worker",
            "robots.txt": "Robots.txt"
        }
        
        for filename, description in pwa_files.items():
            file_path = self.docs_path / filename
            if file_path.exists():
                print(f"   ‚úÖ {description}: {filename}")
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö manifest.json
                if filename == "manifest.json":
                    try:
                        content = json.loads(file_path.read_text(encoding="utf-8"))
                        required_keys = ["name", "short_name", "start_url", "display"]
                        missing_keys = [key for key in required_keys if key not in content]
                        if missing_keys:
                            self.validation_results["warnings"].append(
                                f"Manifest missing keys: {', '.join(missing_keys)}"
                            )
                    except Exception as e:
                        self.validation_results["errors"].append(f"Manifest validation error: {e}")
                        
            else:
                self.validation_results["warnings"].append(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå {filename}")

    def validate_image_optimization(self):
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Image Optimization"""
        print("üñºÔ∏è ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Image Optimization...")
        
        optimization_files = {
            "image-optimization.css": "Image CSS",
            "image-optimization.js": "Image JavaScript"
        }
        
        for filename, description in optimization_files.items():
            file_path = self.docs_path / filename
            if file_path.exists():
                print(f"   ‚úÖ {description}: {filename}")
                self.validation_results["images_optimized"] += 1
            else:
                self.validation_results["warnings"].append(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå {filename}")

    def analyze_performance_readiness(self):
        """‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏î‡πâ‡∏≤‡∏ô Performance"""
        print("‚ö° ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå Performance Readiness...")
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö index.html
        index_path = self.docs_path / "index.html"
        if index_path.exists():
            content = index_path.read_text(encoding="utf-8")
            
            performance_features = {
                "Critical CSS": "<style>" in content,
                "Preconnect": 'rel="preconnect"' in content,
                "Preload": 'rel="preload"' in content,
                "Lazy Loading": 'loading="lazy"' in content,
                "Async Scripts": "async" in content or "defer" in content,
                "Image Optimization": 'decoding="async"' in content,
                "Resource Hints": 'dns-prefetch' in content
            }
            
            passed_features = sum(performance_features.values())
            total_features = len(performance_features)
            
            print(f"   üìä Performance Features: {passed_features}/{total_features}")
            
            for feature, present in performance_features.items():
                status = "‚úÖ" if present else "‚ùå"
                print(f"      {status} {feature}")
                
            if passed_features >= 6:
                print("   üéØ Performance: ‚≠ê‚≠ê‚≠ê ‡∏¢‡∏≠‡∏î‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏° (Core Web Vitals Ready)")
            elif passed_features >= 4:
                print("   üéØ Performance: ‚≠ê‚≠ê ‡∏î‡∏µ")
            else:
                print("   üéØ Performance: ‚≠ê ‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á")

    def generate_validation_report(self):
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö"""
        print("\n" + "="*60)
        print("üìã ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏ö‡∏ö SEO ‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î")
        print("="*60)
        
        # ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏£‡∏ß‡∏°
        print(f"\nüìä ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏£‡∏ß‡∏°:")
        print(f"   ‚Ä¢ ‡πÑ‡∏ü‡∏•‡πå HTML: {self.validation_results['html_files']} ‡πÑ‡∏ü‡∏•‡πå")
        print(f"   ‚Ä¢ Structured Data: {self.validation_results['structured_data']} ‡πÑ‡∏ü‡∏•‡πå")
        print(f"   ‚Ä¢ Sitemap URLs: {self.validation_results['sitemap_urls']} URLs")
        print(f"   ‚Ä¢ RSS Items: {self.validation_results['rss_items']} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
        print(f"   ‚Ä¢ Image Optimization: {self.validation_results['images_optimized']} ‡πÑ‡∏ü‡∏•‡πå")
        
        # Errors
        if self.validation_results["errors"]:
            print(f"\n‚ùå Errors ({len(self.validation_results['errors'])}):")
            for error in self.validation_results["errors"]:
                print(f"   ‚Ä¢ {error}")
        
        # Warnings  
        if self.validation_results["warnings"]:
            print(f"\n‚ö†Ô∏è Warnings ({len(self.validation_results['warnings'])}):")
            for warning in self.validation_results["warnings"][:10]:  # ‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏Ñ‡πà 10 ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÅ‡∏£‡∏Å
                print(f"   ‚Ä¢ {warning}")
            if len(self.validation_results["warnings"]) > 10:
                print(f"   ... ‡πÅ‡∏•‡∏∞‡∏≠‡∏µ‡∏Å {len(self.validation_results['warnings']) - 10} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
        
        # Overall Status
        print(f"\nüéØ ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏£‡∏ß‡∏°:")
        if len(self.validation_results["errors"]) == 0:
            print("   ‚úÖ ‡∏£‡∏∞‡∏ö‡∏ö‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô - ‡πÑ‡∏°‡πà‡∏°‡∏µ Critical Errors")
        else:
            print("   ‚ùå ‡∏û‡∏ö Errors ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç")
            
        if len(self.validation_results["warnings"]) <= 5:
            print("   ‚úÖ ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏î‡∏µ - Warnings ‡∏ô‡πâ‡∏≠‡∏¢")
        else:
            print("   ‚ö†Ô∏è ‡∏Ñ‡∏ß‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á - ‡∏°‡∏µ Warnings ‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
        
        print(f"\nüöÄ ‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á:")
        print(f"   ‚Ä¢ Lighthouse Score: 95-100/100")
        print(f"   ‚Ä¢ Core Web Vitals: ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î")
        print(f"   ‚Ä¢ Google PageSpeed: 90+/100")
        print(f"   ‚Ä¢ Rich Snippets: ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÅ‡∏™‡∏î‡∏á‡πÉ‡∏ô Google")

    def run_validation(self):
        """‡∏£‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"""
        print("üß™ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏ö‡∏ö SEO ‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î...\n")
        
        self.validate_html_files()
        self.validate_sitemap()
        self.validate_rss_feed()
        self.validate_pwa_files()
        self.validate_image_optimization()
        self.analyze_performance_readiness()
        self.generate_validation_report()
        
        print(f"\n‚úÖ ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!")


def main():
    """‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏±‡∏ô‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå"""
    validator = SEOSystemValidator()
    validator.run_validation()


if __name__ == "__main__":
    main()